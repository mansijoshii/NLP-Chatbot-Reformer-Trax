{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Reformer_Chatbot_Trax_TrainedFromScratch.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GV9XpYC8M6xJ"
      },
      "source": [
        "# Chatbot Implementation with Reformer\n",
        "---\n",
        "\n",
        "last updated: Nov 08, 2020"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhxToR5JSV1D"
      },
      "source": [
        "### References\n",
        "\n",
        "This notebook was learned and modified from the assignment of the course [Natural Language Processing with Attention Models](https://www.coursera.org/learn/attention-models-in-nlp) on *Coursera* with the following amendments:\n",
        "\n",
        "1. Instead of using a pre-trained model, I trained the chatbot **from scratch**\n",
        "\n",
        "2. Instead of using `trax.supervised.decoding.autoregressive_sample_stream`, I used a helper function to continue the conversation token by token.\n",
        "\n",
        "3. I cleaned up and rewrited the part of model evaluation. The model can be used to predict on the test dataset, or any custom starter sentence.\n",
        "---\n",
        "\n",
        "### Project Summary\n",
        "\n",
        "1. After training on the MultiWOZ dataset (trainning size = 9,938) for 20,000 epochs, the model achieved the **accuracy of 67.15%** on the test set (size = 500).\n",
        "\n",
        "2. By feeding in some custom stencences, the **chatbot is able to handle the conversation and address the request**. For example conversations, please go to *Step 6-4-3* (at the end of this notebook).\n",
        "\n",
        "---\n",
        "### The Reformer Paper\n",
        "\n",
        "N. Kitaev et al., **Reformer: The Efficient Transformer**\n",
        "\n",
        "https://arxiv.org/abs/2001.04451\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZvmX9BUM-JH"
      },
      "source": [
        "## Step 1: Install prerequisites"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6bFrP5vWSfG"
      },
      "source": [
        "### 1-1 Install Trax"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vuu8xGgBMy2j"
      },
      "source": [
        "!pip -q install trax"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HOmoyhg9NAdA"
      },
      "source": [
        "### 1-2 Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTPh6cTCM_lS"
      },
      "source": [
        "import json\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "import trax\n",
        "from trax import layers as tl\n",
        "from trax.supervised import training\n",
        "\n",
        "from termcolor import colored"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hk-AftcrPIlr"
      },
      "source": [
        "## Step 2: Download and Upload the Dataset\n",
        "\n",
        "---\n",
        "\n",
        "**Whcih dataset?**\n",
        "\n",
        "Datasets of dialogues can be chosen from the following website:\n",
        "\n",
        "https://lionbridge.ai/datasets/15-best-chatbot-datasets-for-machine-learning/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95_fR4l2WrJP"
      },
      "source": [
        "This is the dataset I used:\n",
        "\n",
        "\n",
        "**MultiWOZ: Multi-Domain Wizard-of-Oz dataset (ver 2.1)**\n",
        "\n",
        "http://dialogue.mi.eng.cam.ac.uk/index.php/corpus/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5gZmyU9iW1Dc"
      },
      "source": [
        "### 2-1 Download the dataset\n",
        "\n",
        "Download the dataset `data.json` (263MB) from the website above"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ygHfEUDW-Hs"
      },
      "source": [
        "### 2-2 Upload the dataset\n",
        "\n",
        "Upload `data.json` to the current directory. It may take a while."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7VqL6-Ubf1TF"
      },
      "source": [
        "### 2-3 Load the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5u67aEdmNIvQ"
      },
      "source": [
        "with open('data.json') as file:\n",
        "    multiwoz_dataset_json = json.load(file)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRiyUKVkf7RQ"
      },
      "source": [
        "### 2-4 Inspect the data format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxHPxFBzSNAG",
        "outputId": "6fcdb2f3-0a40-4f54-bff4-364d011f2971",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(\"Dataset loaded. Number of dialogues: {}\".format(len(multiwoz_dataset_json)))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset loaded. Number of dialogues: 10438\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRdS6CNCSQV_",
        "outputId": "4ac6fab7-f67a-4bb7-b56d-8482534d4b36",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(multiwoz_dataset_json['SNG01856.json'].keys())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['goal', 'log'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "px6lZ6DBSV8H",
        "outputId": "345075f2-1c96-45af-fcdf-cf0b4e620e42",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(multiwoz_dataset_json['SNG01856.json']['log'])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[{'text': 'am looking for a place to to stay that has cheap price range it should be in a type of hotel', 'metadata': {}}, {'text': 'Okay, do you have a specific area you want to stay in?', 'metadata': {'taxi': {'book': {'booked': []}, 'semi': {'leaveAt': '', 'destination': '', 'departure': '', 'arriveBy': ''}}, 'police': {'book': {'booked': []}, 'semi': {}}, 'restaurant': {'book': {'booked': [], 'time': '', 'day': '', 'people': ''}, 'semi': {'food': '', 'pricerange': '', 'name': '', 'area': ''}}, 'hospital': {'book': {'booked': []}, 'semi': {'department': ''}}, 'hotel': {'book': {'booked': [], 'stay': '', 'day': '', 'people': ''}, 'semi': {'name': 'not mentioned', 'area': 'not mentioned', 'parking': 'not mentioned', 'pricerange': 'cheap', 'stars': 'not mentioned', 'internet': 'not mentioned', 'type': 'hotel'}}, 'attraction': {'book': {'booked': []}, 'semi': {'type': '', 'name': '', 'area': ''}}, 'train': {'book': {'booked': [], 'people': ''}, 'semi': {'leaveAt': '', 'destination': '', 'day': '', 'arriveBy': '', 'departure': ''}}}}, {'text': \"no, i just need to make sure it's cheap. oh, and i need parking\", 'metadata': {}}, {'text': 'I found 1 cheap hotel for you that includes parking. Do you like me to book it?', 'metadata': {'taxi': {'book': {'booked': []}, 'semi': {'leaveAt': '', 'destination': '', 'departure': '', 'arriveBy': ''}}, 'police': {'book': {'booked': []}, 'semi': {}}, 'restaurant': {'book': {'booked': [], 'time': '', 'day': '', 'people': ''}, 'semi': {'food': '', 'pricerange': '', 'name': '', 'area': ''}}, 'hospital': {'book': {'booked': []}, 'semi': {'department': ''}}, 'hotel': {'book': {'booked': [], 'stay': '', 'day': '', 'people': ''}, 'semi': {'name': 'not mentioned', 'area': 'not mentioned', 'parking': 'yes', 'pricerange': 'cheap', 'stars': 'not mentioned', 'internet': 'not mentioned', 'type': 'hotel'}}, 'attraction': {'book': {'booked': []}, 'semi': {'type': '', 'name': '', 'area': ''}}, 'train': {'book': {'booked': [], 'people': ''}, 'semi': {'leaveAt': '', 'destination': '', 'day': '', 'arriveBy': '', 'departure': ''}}}}, {'text': 'Yes, please. 6 people 3 nights starting on tuesday.', 'metadata': {}}, {'text': \"I am sorry but I wasn't able to book that for you for Tuesday. Is there another day you would like to stay or perhaps a shorter stay?\", 'metadata': {'taxi': {'book': {'booked': []}, 'semi': {'leaveAt': '', 'destination': '', 'departure': '', 'arriveBy': ''}}, 'police': {'book': {'booked': []}, 'semi': {}}, 'restaurant': {'book': {'booked': [], 'time': '', 'day': '', 'people': ''}, 'semi': {'food': '', 'pricerange': '', 'name': '', 'area': ''}}, 'hospital': {'book': {'booked': []}, 'semi': {'department': ''}}, 'hotel': {'book': {'booked': [], 'stay': '3', 'day': 'tuesday', 'people': '6'}, 'semi': {'name': 'not mentioned', 'area': 'not mentioned', 'parking': 'yes', 'pricerange': 'cheap', 'stars': 'not mentioned', 'internet': 'not mentioned', 'type': 'hotel'}}, 'attraction': {'book': {'booked': []}, 'semi': {'type': '', 'name': '', 'area': ''}}, 'train': {'book': {'booked': [], 'people': ''}, 'semi': {'leaveAt': '', 'destination': '', 'day': '', 'arriveBy': '', 'departure': ''}}}}, {'text': 'how about only 2 nights.', 'metadata': {}}, {'text': 'Booking was successful.\\nReference number is : 7GAWK763. Anything else I can do for you?', 'metadata': {'taxi': {'book': {'booked': []}, 'semi': {'leaveAt': '', 'destination': '', 'departure': '', 'arriveBy': ''}}, 'police': {'book': {'booked': []}, 'semi': {}}, 'restaurant': {'book': {'booked': [], 'time': '', 'day': '', 'people': ''}, 'semi': {'food': '', 'pricerange': '', 'name': '', 'area': ''}}, 'hospital': {'book': {'booked': []}, 'semi': {'department': ''}}, 'hotel': {'book': {'booked': [{'name': 'the cambridge belfry', 'reference': '7GAWK763'}], 'stay': '2', 'day': 'tuesday', 'people': '6'}, 'semi': {'name': 'not mentioned', 'area': 'not mentioned', 'parking': 'yes', 'pricerange': 'cheap', 'stars': 'not mentioned', 'internet': 'not mentioned', 'type': 'hotel'}}, 'attraction': {'book': {'booked': []}, 'semi': {'type': '', 'name': '', 'area': ''}}, 'train': {'book': {'booked': [], 'people': ''}, 'semi': {'leaveAt': '', 'destination': '', 'day': '', 'arriveBy': '', 'departure': ''}}}}, {'text': 'No, that will be all. Good bye.', 'metadata': {}}, {'text': 'Thank you for using our services.', 'metadata': {'taxi': {'book': {'booked': []}, 'semi': {'leaveAt': '', 'destination': '', 'departure': '', 'arriveBy': ''}}, 'police': {'book': {'booked': []}, 'semi': {}}, 'restaurant': {'book': {'booked': [], 'time': '', 'day': '', 'people': ''}, 'semi': {'food': '', 'pricerange': '', 'name': '', 'area': ''}}, 'hospital': {'book': {'booked': []}, 'semi': {'department': ''}}, 'hotel': {'book': {'booked': [{'name': 'the cambridge belfry', 'reference': '7GAWK763'}], 'stay': '2', 'day': 'tuesday', 'people': '6'}, 'semi': {'name': 'not mentioned', 'area': 'not mentioned', 'parking': 'yes', 'pricerange': 'cheap', 'stars': 'not mentioned', 'internet': 'not mentioned', 'type': 'hotel'}}, 'attraction': {'book': {'booked': []}, 'semi': {'type': '', 'name': '', 'area': ''}}, 'train': {'book': {'booked': [], 'people': ''}, 'semi': {'leaveAt': '', 'destination': '', 'day': '', 'arriveBy': '', 'departure': ''}}}}]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lvf4nbnNTQwe",
        "outputId": "57286740-fc47-4bb5-cbbd-1a52ec41655c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "## Displayed a dialogue with colors\n",
        "\n",
        "sample_dialogue = multiwoz_dataset_json['SNG0129.json']['log']\n",
        "\n",
        "for i in range(len(sample_dialogue)):\n",
        "    if i % 2 == 0:\n",
        "        print(colored(sample_dialogue[i]['text'], 'blue'))\n",
        "    else:\n",
        "        print(colored(sample_dialogue[i]['text'], 'red'))\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34mHello, I have been robbed.  Can you please help me get in touch with the police?\u001b[0m\n",
            "\u001b[31mParkside Police Station is in Parkside, Cambridge. Their number is 01223358966. Anything else I can do for you?\u001b[0m\n",
            "\u001b[34mCan I please have the postcode as well?\u001b[0m\n",
            "\u001b[31mThe postcode for the Parkside Police Station is CB11JG. Can I help you with anything else?\u001b[0m\n",
            "\u001b[34mWas Parkside the address of the police station? If not, can I have the address please?\u001b[0m\n",
            "\u001b[31mYes, Parkside is the address.\u001b[0m\n",
            "\u001b[34mThank you that will be all for now.\u001b[0m\n",
            "\u001b[31mGreat. Thank you for contacting Cambridge Towninfo Centre.\u001b[0m\n",
            "\u001b[34mYou were great. Goodbye.\u001b[0m\n",
            "\u001b[31mWe are happy to help. Have a good day!\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37Hjiv8xSYZz"
      },
      "source": [
        "## Step 3: Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNKxqlq1gLd5"
      },
      "source": [
        "### 3-1 Add \"Person 1\" and \"Person 2\" into the dialogue"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ke6WWPX1SZ_B"
      },
      "source": [
        "dialogue_sentences_list = []\n",
        "\n",
        "for json_index in multiwoz_dataset_json.keys():\n",
        "    \n",
        "    dialogue = multiwoz_dataset_json[json_index]['log']\n",
        "\n",
        "    dialogue_sentences_str = \"\"\n",
        "\n",
        "    for i in range(len(dialogue)):\n",
        "\n",
        "        if i % 2 == 0:\n",
        "            dialogue_sentences_str += \" Person 1: \" + dialogue[i]['text']\n",
        "        else:\n",
        "            dialogue_sentences_str += \" Person 2: \" + dialogue[i]['text']\n",
        "    \n",
        "    dialogue_sentences_list.append(dialogue_sentences_str)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SByscthTUzV5",
        "outputId": "9511b686-11df-4685-8e3f-cb2d1cead4ba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(len(dialogue_sentences_list))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10438\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWdBAMHvWEqs",
        "outputId": "da568c22-dde3-4337-f6bd-e258e43842e8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(dialogue_sentences_list[0])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Person 1: am looking for a place to to stay that has cheap price range it should be in a type of hotel Person 2: Okay, do you have a specific area you want to stay in? Person 1: no, i just need to make sure it's cheap. oh, and i need parking Person 2: I found 1 cheap hotel for you that includes parking. Do you like me to book it? Person 1: Yes, please. 6 people 3 nights starting on tuesday. Person 2: I am sorry but I wasn't able to book that for you for Tuesday. Is there another day you would like to stay or perhaps a shorter stay? Person 1: how about only 2 nights. Person 2: Booking was successful.\n",
            "Reference number is : 7GAWK763. Anything else I can do for you? Person 1: No, that will be all. Good bye. Person 2: Thank you for using our services.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wq4L2LyfgdmD"
      },
      "source": [
        "### 3-2 Shuffle the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RTtESb-WGS-"
      },
      "source": [
        "## shuffle the list\n",
        "random.shuffle(dialogue_sentences_list)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HeJfVsCkgh5F"
      },
      "source": [
        "### 3-3 Split into training and test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_JGLwyjWTMC",
        "outputId": "9b2915c1-099e-4ead-ab11-231d4aa09d37",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "## Split 500 dialogues to the test dataset\n",
        "train_data, test_data = dialogue_sentences_list[:-500], dialogue_sentences_list[-500:]\n",
        "\n",
        "print(\"Number of train_data: {}\".format(len(train_data)))\n",
        "print(\"Number of test_data: {}\".format(len(test_data)))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of train_data: 9938\n",
            "Number of test_data: 500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FpYto2vSOl1",
        "outputId": "5776fc6d-0f2f-4967-d43b-7761c9031094",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(train_data[0])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Person 1: I am looking for places to go in the north area. Person 2: I have a boat, park or 2 swimming pools in that area. Is there one you would like to try? Person 1: Give me more information about the boat please. Person 2: The address to riverboat georgina is cambridge passenger cruisers, jubilee house and the postcode is cb43ax. Can I help with anything else? Person 1: I'm looking for a place to eat that is in the same area. I want it to be cheap.  Person 2: You've got 2 choices in the north for cheap places to eat: Royal Spice serves Indian food, and Da Vinci Pizzeria serves Italian food. Which would you prefer? Person 1: Da Vinci Pizzeria sounds good.  Thanks. Person 2: For how many do you need this reservation? Person 1: I need to book a table for 8 at 18:30 on Monday, please. Person 2: Your table is reserved at DaVinci, ref# 6U1JO0B2. Is there anything else I can do for you today? Person 1: I also need a taxi that will get me  to the restaurant in time for the booking you just made. Person 2: Excellent, I have booked you a taxi, a yellow skoda, and the contact number is 07262084765. Is there anything else I can help with?  Person 1: No, I think this is all I need for today.  Thank you for your help today. Person 2: You're welcome. Enjoy the rest of your day! Goodbye.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BF16ATBoSQoe",
        "outputId": "58de76d6-1f82-4391-8e1b-c8795a11231d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(test_data[0])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Person 1: Hello, do you have any information regarding interesting theatres to visit in the centre of town? Person 2: Sure thing, there are four theatres in the centre of town. ADC Theatre, Cambridge Arts Theatre, Mumford Theatre, and The Cambridge Corn Exchange.  Person 1: I'm interested in one of the theatres! Can I get the entrance fee information for those? Person 2: I'm sorry, but none of the theaters list the entrance fee. Would you like the phone number for any of them? Person 1: That's okay, could you provide me with the postcode and address, please? Also, I am looking for a train leaving after 16:00 this Monday. Person 2: The ADC Theatre is located on Park Street and its postcode is cb23pj. Before I find your train, could you tell me where you would like to go? Person 1: Of course, silly me :P I am looking for a train from cambridge to stevenage Person 2: The TR0254 leaves Cambridge at 17:21. Person 1: Awesome, thank you very much! I'm pretty sure that's all I need right now, but I'll be back if I think of anything else. Later! Person 2: Great thank you for using our system.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RKIKAzJbgsB2"
      },
      "source": [
        "### 3-4 Remove leading or ending white spaces"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbRGO52HTBZ-"
      },
      "source": [
        "for i in range(len(train_data)):\n",
        "    train_data[i] = train_data[i].strip()\n",
        "\n",
        "for i in range(len(test_data)):\n",
        "    test_data[i] = test_data[i].strip()"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K73x3FsOW3KF"
      },
      "source": [
        "### 3-5 Data pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Y5tGPSyWzBY"
      },
      "source": [
        "def stream_generator(data):\n",
        "    while True:\n",
        "        x = random.choice(data)\n",
        "        yield (x, x)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNeOnAy4XPQ7"
      },
      "source": [
        "data_pipeline = trax.data.Serial(trax.data.Shuffle(),\n",
        "                                 trax.data.Tokenize(vocab_file = 'en_32k.subword'),\n",
        "                                 trax.data.FilterByLength(2048),\n",
        "                                 trax.data.BucketByLength(boundaries = [128, 256, 512, 1024], batch_sizes = [16, 8, 4, 2, 1]),\n",
        "                                 trax.data.AddLossWeights(id_to_mask = 0))\n",
        "\n",
        "train_stream = data_pipeline(stream_generator(train_data))\n",
        "test_stream = data_pipeline(stream_generator(test_data))"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upJuSFR1Uk4l",
        "outputId": "0887336e-716d-47ac-c520-5e111a838d98",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "## Check 1\n",
        "# (input, target, weights)\n",
        "\n",
        "print(\"train_stream\")\n",
        "print(next(train_stream))\n",
        "print(\"\\ntest_stream\")\n",
        "print(next(test_stream))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_stream\n",
            "(array([[8745,    3,   54, ...,    0,    0,    0],\n",
            "       [8745,    3,   54, ...,    0,    0,    0],\n",
            "       [8745,    3,   54, ...,    0,    0,    0],\n",
            "       [8745,    3,   54, ...,    0,    0,    0]]), array([[8745,    3,   54, ...,    0,    0,    0],\n",
            "       [8745,    3,   54, ...,    0,    0,    0],\n",
            "       [8745,    3,   54, ...,    0,    0,    0],\n",
            "       [8745,    3,   54, ...,    0,    0,    0]]), array([[1., 1., 1., ..., 0., 0., 0.],\n",
            "       [1., 1., 1., ..., 0., 0., 0.],\n",
            "       [1., 1., 1., ..., 0., 0., 0.],\n",
            "       [1., 1., 1., ..., 0., 0., 0.]], dtype=float32))\n",
            "\n",
            "test_stream\n",
            "(array([[8745,    3,   54, ...,    0,    0,    0],\n",
            "       [8745,    3,   54, ...,    0,    0,    0],\n",
            "       [8745,    3,   54, ...,    0,    0,    0],\n",
            "       [8745,    3,   54, ...,    0,    0,    0]]), array([[8745,    3,   54, ...,    0,    0,    0],\n",
            "       [8745,    3,   54, ...,    0,    0,    0],\n",
            "       [8745,    3,   54, ...,    0,    0,    0],\n",
            "       [8745,    3,   54, ...,    0,    0,    0]]), array([[1., 1., 1., ..., 0., 0., 0.],\n",
            "       [1., 1., 1., ..., 0., 0., 0.],\n",
            "       [1., 1., 1., ..., 0., 0., 0.],\n",
            "       [1., 1., 1., ..., 0., 0., 0.]], dtype=float32))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kphy-pkgYfcn",
        "outputId": "c753e213-cad1-42f2-9858-52abaae85ec1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "## Check\n",
        "\n",
        "x = next(train_stream)[0]\n",
        "y = next(test_stream)\n",
        "\n",
        "print(x.shape)\n",
        "print(x)\n",
        "\n",
        "y = trax.data.detokenize(x[0], vocab_file = 'en_32k.subword')\n",
        "\n",
        "print(y)\n",
        "\n",
        "del x, y"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4, 512)\n",
            "[[8745    3   54 ...    0    0    0]\n",
            " [8745    3   54 ...    0    0    0]\n",
            " [8745    3   54 ...    0    0    0]\n",
            " [8745    3   54 ...    0    0    0]]\n",
            "Person 1: Please dig up some information on the mutliple sports in the centre for me Person 2: I'm afraid there isn't one. Can I help you find something else? Person 1: Oh well. I guess maybe a theatre instead.  Person 2: There are 4 theatres in the centre. They are adc theatre, cambridge arts theatre, mumford theatre, and the cambridge corn exchange. Person 1: Can you tell me the postcode, entrance fee, and phone number of adc theatre? Person 2: The entrance fee isn't listed, but you can reach them by phone at 01223300085. The postcode is cb58as. Person 1: Thanks I also need a train that's going to cambridge.  Person 2: No problem, where will that be coming from? Person 1: I need to leave from Norwich sometime after 20:15 on Saturday. Person 2: TR0615 departs at 20:16 and arrives by 21:35. Would you like a ticket? Person 1: No.  That is all the info I need.  Person 2: Ok, have a good day!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OeFwIsGxbZTr"
      },
      "source": [
        "## Step 4: Create the Reformer model\n",
        "\n",
        "**Trax Documentation**\n",
        "\n",
        "[trax.models.reformer.ReformerLM](https://trax-ml.readthedocs.io/en/latest/trax.models.html#trax.models.reformer.reformer.ReformerLM)\n",
        "\n",
        "This model only uses the decoder (no encoder).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_X46wxVbawA",
        "outputId": "7341261d-ba66-477e-9eb5-3525be2a4924",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def ReformerLM(vocab_size = 33000, n_layers = 6, mode = 'train', attention_type = tl.SelfAttention):\n",
        "\n",
        "    \"\"\"\n",
        "    Create the Reformer\n",
        "\n",
        "    Inputs\n",
        "            vocab_size: <int> the size of the vocabulary\n",
        "            n_layers: <int> number of decoder layers\n",
        "            mode: <str> 'train', 'eval', or 'predict'\n",
        "            attention_type: <trax class> type of the attention class\n",
        "\n",
        "    Output\n",
        "            model: <trax model> the Reformer model\n",
        "    \"\"\"\n",
        "\n",
        "    model = trax.models.reformer.ReformerLM(vocab_size = vocab_size,\n",
        "                                            n_layers = n_layers,\n",
        "                                            mode = mode,\n",
        "                                            attention_type = attention_type)\n",
        "\n",
        "    return model\n",
        "\n",
        "## Check\n",
        "model = ReformerLM(mode = 'train')\n",
        "print(str(model))\n",
        "del model "
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Serial[\n",
            "  Serial[\n",
            "    AssertShape\n",
            "    ShiftRight(1)\n",
            "    AssertShape\n",
            "  ]\n",
            "  Embedding_33000_512\n",
            "  Dropout\n",
            "  PositionalEncoding\n",
            "  Dup_out2\n",
            "  ReversibleSerial_in2_out2[\n",
            "    ReversibleHalfResidual_in2_out2[\n",
            "      Serial[\n",
            "        LayerNorm\n",
            "      ]\n",
            "      SelfAttention\n",
            "    ]\n",
            "    ReversibleSwap_in2_out2\n",
            "    ReversibleHalfResidual_in2_out2[\n",
            "      Serial[\n",
            "        LayerNorm\n",
            "        Dense_2048\n",
            "        Dropout\n",
            "        FastGelu\n",
            "        Dense_512\n",
            "        Dropout\n",
            "      ]\n",
            "    ]\n",
            "    ReversibleSwap_in2_out2\n",
            "    ReversibleHalfResidual_in2_out2[\n",
            "      Serial[\n",
            "        LayerNorm\n",
            "      ]\n",
            "      SelfAttention\n",
            "    ]\n",
            "    ReversibleSwap_in2_out2\n",
            "    ReversibleHalfResidual_in2_out2[\n",
            "      Serial[\n",
            "        LayerNorm\n",
            "        Dense_2048\n",
            "        Dropout\n",
            "        FastGelu\n",
            "        Dense_512\n",
            "        Dropout\n",
            "      ]\n",
            "    ]\n",
            "    ReversibleSwap_in2_out2\n",
            "    ReversibleHalfResidual_in2_out2[\n",
            "      Serial[\n",
            "        LayerNorm\n",
            "      ]\n",
            "      SelfAttention\n",
            "    ]\n",
            "    ReversibleSwap_in2_out2\n",
            "    ReversibleHalfResidual_in2_out2[\n",
            "      Serial[\n",
            "        LayerNorm\n",
            "        Dense_2048\n",
            "        Dropout\n",
            "        FastGelu\n",
            "        Dense_512\n",
            "        Dropout\n",
            "      ]\n",
            "    ]\n",
            "    ReversibleSwap_in2_out2\n",
            "    ReversibleHalfResidual_in2_out2[\n",
            "      Serial[\n",
            "        LayerNorm\n",
            "      ]\n",
            "      SelfAttention\n",
            "    ]\n",
            "    ReversibleSwap_in2_out2\n",
            "    ReversibleHalfResidual_in2_out2[\n",
            "      Serial[\n",
            "        LayerNorm\n",
            "        Dense_2048\n",
            "        Dropout\n",
            "        FastGelu\n",
            "        Dense_512\n",
            "        Dropout\n",
            "      ]\n",
            "    ]\n",
            "    ReversibleSwap_in2_out2\n",
            "    ReversibleHalfResidual_in2_out2[\n",
            "      Serial[\n",
            "        LayerNorm\n",
            "      ]\n",
            "      SelfAttention\n",
            "    ]\n",
            "    ReversibleSwap_in2_out2\n",
            "    ReversibleHalfResidual_in2_out2[\n",
            "      Serial[\n",
            "        LayerNorm\n",
            "        Dense_2048\n",
            "        Dropout\n",
            "        FastGelu\n",
            "        Dense_512\n",
            "        Dropout\n",
            "      ]\n",
            "    ]\n",
            "    ReversibleSwap_in2_out2\n",
            "    ReversibleHalfResidual_in2_out2[\n",
            "      Serial[\n",
            "        LayerNorm\n",
            "      ]\n",
            "      SelfAttention\n",
            "    ]\n",
            "    ReversibleSwap_in2_out2\n",
            "    ReversibleHalfResidual_in2_out2[\n",
            "      Serial[\n",
            "        LayerNorm\n",
            "        Dense_2048\n",
            "        Dropout\n",
            "        FastGelu\n",
            "        Dense_512\n",
            "        Dropout\n",
            "      ]\n",
            "    ]\n",
            "    ReversibleSwap_in2_out2\n",
            "  ]\n",
            "  Concatenate_in2\n",
            "  LayerNorm\n",
            "  Dropout\n",
            "  Dense_33000\n",
            "  LogSoftmax\n",
            "]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S4b2Cq80dRyA"
      },
      "source": [
        "## Step 5: Train the Reformer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eI5TilXzjEJb"
      },
      "source": [
        "### 5-1 The training loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2NaOL-CYdHLu"
      },
      "source": [
        "def training_loop(ReformerLM, train_generator, eval_generator):\n",
        "\n",
        "    \"\"\"\n",
        "    Create the training loop\n",
        "\n",
        "    Inputs\n",
        "            ReformerLM: <Trax model> the Reformer model\n",
        "            train_generator: <Trax stream> the generator stream of training data\n",
        "            eval_generator: <Trax stream> the generator stream of the test data\n",
        "    \n",
        "    Output\n",
        "            loop: <Trax loop object> the loop object\n",
        "    \"\"\"\n",
        "\n",
        "    # schedule of the learning rate\n",
        "    lr_schedule = trax.lr.warmup_and_rsqrt_decay(n_warmup_steps = 4000, max_value = 0.001)\n",
        "\n",
        "    # the training task\n",
        "    train_task = training.TrainTask(labeled_data = train_generator,\n",
        "                                    loss_layer = tl.CrossEntropyLoss(),\n",
        "                                    optimizer = trax.optimizers.Adam(0.001),\n",
        "                                    lr_schedule = lr_schedule,\n",
        "                                    n_steps_per_checkpoint = 200)\n",
        "    \n",
        "    # the evaluation task\n",
        "    eval_task = training.EvalTask(labeled_data = eval_generator,\n",
        "                                  metrics = [tl.CrossEntropyLoss(), tl.Accuracy()])\n",
        "    \n",
        "    # create the loop object\n",
        "    loop = training.Loop(model = ReformerLM(mode = 'train'),\n",
        "                         tasks = [train_task],\n",
        "                         eval_tasks = [eval_task],\n",
        "                         output_dir = '.')\n",
        "    \n",
        "    return loop"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNEL5QtGocxe"
      },
      "source": [
        "### 5-2 Train the model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVdn_dweBOgL",
        "outputId": "bd0a761f-3a76-4810-9147-c46037bfeeba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "## This box needs to be executed if training_loop has been run before\n",
        "!rm model.pkl.gz\n",
        "!rm config.gin\n",
        "!rm -r train\n",
        "!rm -r eval"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove 'model.pkl.gz': No such file or directory\n",
            "rm: cannot remove 'config.gin': No such file or directory\n",
            "rm: cannot remove 'train': No such file or directory\n",
            "rm: cannot remove 'eval': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrcCsbc8odV-",
        "outputId": "c3991a95-f62c-4216-e97f-8c058bd60f89",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "loop = training_loop(ReformerLM, train_stream, test_stream)\n",
        "loop.run(20000)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Step      1: Total number of trainable weights: 70673640\n",
            "Step      1: Ran 1 train steps in 60.75 secs\n",
            "Step      1: train CrossEntropyLoss |  10.44453430\n",
            "Step      1: eval  CrossEntropyLoss |  10.43628788\n",
            "Step      1: eval          Accuracy |  0.00000000\n",
            "\n",
            "Step    200: Ran 199 train steps in 131.59 secs\n",
            "Step    200: train CrossEntropyLoss |  8.29019642\n",
            "Step    200: eval  CrossEntropyLoss |  5.70468712\n",
            "Step    200: eval          Accuracy |  0.07524613\n",
            "\n",
            "Step    400: Ran 200 train steps in 79.36 secs\n",
            "Step    400: train CrossEntropyLoss |  5.62913370\n",
            "Step    400: eval  CrossEntropyLoss |  5.53083134\n",
            "Step    400: eval          Accuracy |  0.06506850\n",
            "\n",
            "Step    600: Ran 200 train steps in 60.35 secs\n",
            "Step    600: train CrossEntropyLoss |  5.52661419\n",
            "Step    600: eval  CrossEntropyLoss |  5.57809830\n",
            "Step    600: eval          Accuracy |  0.07159904\n",
            "\n",
            "Step    800: Ran 200 train steps in 60.02 secs\n",
            "Step    800: train CrossEntropyLoss |  4.99216938\n",
            "Step    800: eval  CrossEntropyLoss |  4.53790379\n",
            "Step    800: eval          Accuracy |  0.24223208\n",
            "\n",
            "Step   1000: Ran 200 train steps in 59.88 secs\n",
            "Step   1000: train CrossEntropyLoss |  4.22136879\n",
            "Step   1000: eval  CrossEntropyLoss |  4.07758617\n",
            "Step   1000: eval          Accuracy |  0.26235992\n",
            "\n",
            "Step   1200: Ran 200 train steps in 59.86 secs\n",
            "Step   1200: train CrossEntropyLoss |  3.71124339\n",
            "Step   1200: eval  CrossEntropyLoss |  3.47998023\n",
            "Step   1200: eval          Accuracy |  0.33285406\n",
            "\n",
            "Step   1400: Ran 200 train steps in 59.95 secs\n",
            "Step   1400: train CrossEntropyLoss |  3.43183398\n",
            "Step   1400: eval  CrossEntropyLoss |  3.11223006\n",
            "Step   1400: eval          Accuracy |  0.37878788\n",
            "\n",
            "Step   1600: Ran 200 train steps in 60.24 secs\n",
            "Step   1600: train CrossEntropyLoss |  3.20997453\n",
            "Step   1600: eval  CrossEntropyLoss |  3.28944206\n",
            "Step   1600: eval          Accuracy |  0.34133333\n",
            "\n",
            "Step   1800: Ran 200 train steps in 60.52 secs\n",
            "Step   1800: train CrossEntropyLoss |  3.04834318\n",
            "Step   1800: eval  CrossEntropyLoss |  3.02664518\n",
            "Step   1800: eval          Accuracy |  0.38707653\n",
            "\n",
            "Step   2000: Ran 200 train steps in 60.21 secs\n",
            "Step   2000: train CrossEntropyLoss |  2.86785126\n",
            "Step   2000: eval  CrossEntropyLoss |  3.13433099\n",
            "Step   2000: eval          Accuracy |  0.36962250\n",
            "\n",
            "Step   2200: Ran 200 train steps in 60.85 secs\n",
            "Step   2200: train CrossEntropyLoss |  2.75005102\n",
            "Step   2200: eval  CrossEntropyLoss |  2.43542480\n",
            "Step   2200: eval          Accuracy |  0.45994279\n",
            "\n",
            "Step   2400: Ran 200 train steps in 60.22 secs\n",
            "Step   2400: train CrossEntropyLoss |  2.61291885\n",
            "Step   2400: eval  CrossEntropyLoss |  2.75900865\n",
            "Step   2400: eval          Accuracy |  0.42916667\n",
            "\n",
            "Step   2600: Ran 200 train steps in 79.23 secs\n",
            "Step   2600: train CrossEntropyLoss |  2.56970692\n",
            "Step   2600: eval  CrossEntropyLoss |  2.37931323\n",
            "Step   2600: eval          Accuracy |  0.49109882\n",
            "\n",
            "Step   2800: Ran 200 train steps in 59.73 secs\n",
            "Step   2800: train CrossEntropyLoss |  2.44335866\n",
            "Step   2800: eval  CrossEntropyLoss |  2.57452297\n",
            "Step   2800: eval          Accuracy |  0.48548973\n",
            "\n",
            "Step   3000: Ran 200 train steps in 59.97 secs\n",
            "Step   3000: train CrossEntropyLoss |  2.39610314\n",
            "Step   3000: eval  CrossEntropyLoss |  2.55918574\n",
            "Step   3000: eval          Accuracy |  0.48531213\n",
            "\n",
            "Step   3200: Ran 200 train steps in 60.08 secs\n",
            "Step   3200: train CrossEntropyLoss |  2.32993746\n",
            "Step   3200: eval  CrossEntropyLoss |  2.13332701\n",
            "Step   3200: eval          Accuracy |  0.52503210\n",
            "\n",
            "Step   3400: Ran 200 train steps in 59.83 secs\n",
            "Step   3400: train CrossEntropyLoss |  2.24643087\n",
            "Step   3400: eval  CrossEntropyLoss |  2.25088072\n",
            "Step   3400: eval          Accuracy |  0.49933243\n",
            "\n",
            "Step   3600: Ran 200 train steps in 59.41 secs\n",
            "Step   3600: train CrossEntropyLoss |  2.19854832\n",
            "Step   3600: eval  CrossEntropyLoss |  2.16065478\n",
            "Step   3600: eval          Accuracy |  0.53292018\n",
            "\n",
            "Step   3800: Ran 200 train steps in 59.56 secs\n",
            "Step   3800: train CrossEntropyLoss |  2.14376664\n",
            "Step   3800: eval  CrossEntropyLoss |  2.21543860\n",
            "Step   3800: eval          Accuracy |  0.52835411\n",
            "\n",
            "Step   4000: Ran 200 train steps in 59.24 secs\n",
            "Step   4000: train CrossEntropyLoss |  2.24486876\n",
            "Step   4000: eval  CrossEntropyLoss |  2.40257001\n",
            "Step   4000: eval          Accuracy |  0.50113380\n",
            "\n",
            "Step   4200: Ran 200 train steps in 59.39 secs\n",
            "Step   4200: train CrossEntropyLoss |  2.11273360\n",
            "Step   4200: eval  CrossEntropyLoss |  2.22515893\n",
            "Step   4200: eval          Accuracy |  0.50656658\n",
            "\n",
            "Step   4400: Ran 200 train steps in 59.00 secs\n",
            "Step   4400: train CrossEntropyLoss |  2.00955939\n",
            "Step   4400: eval  CrossEntropyLoss |  1.97388649\n",
            "Step   4400: eval          Accuracy |  0.53499329\n",
            "\n",
            "Step   4600: Ran 200 train steps in 59.08 secs\n",
            "Step   4600: train CrossEntropyLoss |  1.98047817\n",
            "Step   4600: eval  CrossEntropyLoss |  1.99315763\n",
            "Step   4600: eval          Accuracy |  0.55215579\n",
            "\n",
            "Step   4800: Ran 200 train steps in 59.17 secs\n",
            "Step   4800: train CrossEntropyLoss |  1.95642304\n",
            "Step   4800: eval  CrossEntropyLoss |  1.91955614\n",
            "Step   4800: eval          Accuracy |  0.55923033\n",
            "\n",
            "Step   5000: Ran 200 train steps in 58.71 secs\n",
            "Step   5000: train CrossEntropyLoss |  1.90284097\n",
            "Step   5000: eval  CrossEntropyLoss |  2.14322543\n",
            "Step   5000: eval          Accuracy |  0.53084648\n",
            "\n",
            "Step   5200: Ran 200 train steps in 58.71 secs\n",
            "Step   5200: train CrossEntropyLoss |  1.89438498\n",
            "Step   5200: eval  CrossEntropyLoss |  2.04274440\n",
            "Step   5200: eval          Accuracy |  0.54067671\n",
            "\n",
            "Step   5400: Ran 200 train steps in 58.72 secs\n",
            "Step   5400: train CrossEntropyLoss |  1.87487745\n",
            "Step   5400: eval  CrossEntropyLoss |  1.87936819\n",
            "Step   5400: eval          Accuracy |  0.56385869\n",
            "\n",
            "Step   5600: Ran 200 train steps in 58.80 secs\n",
            "Step   5600: train CrossEntropyLoss |  1.84744704\n",
            "Step   5600: eval  CrossEntropyLoss |  1.86297655\n",
            "Step   5600: eval          Accuracy |  0.55735666\n",
            "\n",
            "Step   5800: Ran 200 train steps in 58.83 secs\n",
            "Step   5800: train CrossEntropyLoss |  1.81189692\n",
            "Step   5800: eval  CrossEntropyLoss |  1.96394157\n",
            "Step   5800: eval          Accuracy |  0.56059533\n",
            "\n",
            "Step   6000: Ran 200 train steps in 58.54 secs\n",
            "Step   6000: train CrossEntropyLoss |  1.79561341\n",
            "Step   6000: eval  CrossEntropyLoss |  1.57300413\n",
            "Step   6000: eval          Accuracy |  0.63732004\n",
            "\n",
            "Step   6200: Ran 200 train steps in 59.03 secs\n",
            "Step   6200: train CrossEntropyLoss |  1.78741252\n",
            "Step   6200: eval  CrossEntropyLoss |  1.98460519\n",
            "Step   6200: eval          Accuracy |  0.54785025\n",
            "\n",
            "Step   6400: Ran 200 train steps in 58.63 secs\n",
            "Step   6400: train CrossEntropyLoss |  1.78314435\n",
            "Step   6400: eval  CrossEntropyLoss |  2.22564769\n",
            "Step   6400: eval          Accuracy |  0.52248877\n",
            "\n",
            "Step   6600: Ran 200 train steps in 58.63 secs\n",
            "Step   6600: train CrossEntropyLoss |  1.75374067\n",
            "Step   6600: eval  CrossEntropyLoss |  1.78260612\n",
            "Step   6600: eval          Accuracy |  0.58958167\n",
            "\n",
            "Step   6800: Ran 200 train steps in 58.35 secs\n",
            "Step   6800: train CrossEntropyLoss |  1.74827921\n",
            "Step   6800: eval  CrossEntropyLoss |  1.54636753\n",
            "Step   6800: eval          Accuracy |  0.61384904\n",
            "\n",
            "Step   7000: Ran 200 train steps in 77.34 secs\n",
            "Step   7000: train CrossEntropyLoss |  1.73299038\n",
            "Step   7000: eval  CrossEntropyLoss |  1.78283894\n",
            "Step   7000: eval          Accuracy |  0.59307957\n",
            "\n",
            "Step   7200: Ran 200 train steps in 58.74 secs\n",
            "Step   7200: train CrossEntropyLoss |  1.72709143\n",
            "Step   7200: eval  CrossEntropyLoss |  1.73495460\n",
            "Step   7200: eval          Accuracy |  0.59522426\n",
            "\n",
            "Step   7400: Ran 200 train steps in 58.97 secs\n",
            "Step   7400: train CrossEntropyLoss |  1.69668901\n",
            "Step   7400: eval  CrossEntropyLoss |  2.08043075\n",
            "Step   7400: eval          Accuracy |  0.56184900\n",
            "\n",
            "Step   7600: Ran 200 train steps in 58.85 secs\n",
            "Step   7600: train CrossEntropyLoss |  1.69331551\n",
            "Step   7600: eval  CrossEntropyLoss |  1.97555900\n",
            "Step   7600: eval          Accuracy |  0.57415384\n",
            "\n",
            "Step   7800: Ran 200 train steps in 59.07 secs\n",
            "Step   7800: train CrossEntropyLoss |  1.67384338\n",
            "Step   7800: eval  CrossEntropyLoss |  1.78153896\n",
            "Step   7800: eval          Accuracy |  0.58013701\n",
            "\n",
            "Step   8000: Ran 200 train steps in 58.72 secs\n",
            "Step   8000: train CrossEntropyLoss |  1.68245053\n",
            "Step   8000: eval  CrossEntropyLoss |  1.67520678\n",
            "Step   8000: eval          Accuracy |  0.60126084\n",
            "\n",
            "Step   8200: Ran 200 train steps in 59.02 secs\n",
            "Step   8200: train CrossEntropyLoss |  1.66049981\n",
            "Step   8200: eval  CrossEntropyLoss |  1.65375459\n",
            "Step   8200: eval          Accuracy |  0.62685561\n",
            "\n",
            "Step   8400: Ran 200 train steps in 59.15 secs\n",
            "Step   8400: train CrossEntropyLoss |  1.62901390\n",
            "Step   8400: eval  CrossEntropyLoss |  1.58911610\n",
            "Step   8400: eval          Accuracy |  0.60894942\n",
            "\n",
            "Step   8600: Ran 200 train steps in 59.50 secs\n",
            "Step   8600: train CrossEntropyLoss |  1.64011896\n",
            "Step   8600: eval  CrossEntropyLoss |  1.83011210\n",
            "Step   8600: eval          Accuracy |  0.57073462\n",
            "\n",
            "Step   8800: Ran 200 train steps in 59.83 secs\n",
            "Step   8800: train CrossEntropyLoss |  1.64087582\n",
            "Step   8800: eval  CrossEntropyLoss |  1.80370426\n",
            "Step   8800: eval          Accuracy |  0.57234317\n",
            "\n",
            "Step   9000: Ran 200 train steps in 59.57 secs\n",
            "Step   9000: train CrossEntropyLoss |  1.62349367\n",
            "Step   9000: eval  CrossEntropyLoss |  1.73225617\n",
            "Step   9000: eval          Accuracy |  0.59788030\n",
            "\n",
            "Step   9200: Ran 200 train steps in 59.56 secs\n",
            "Step   9200: train CrossEntropyLoss |  1.60244155\n",
            "Step   9200: eval  CrossEntropyLoss |  1.90922177\n",
            "Step   9200: eval          Accuracy |  0.57594383\n",
            "\n",
            "Step   9400: Ran 200 train steps in 59.28 secs\n",
            "Step   9400: train CrossEntropyLoss |  1.60984540\n",
            "Step   9400: eval  CrossEntropyLoss |  1.69360900\n",
            "Step   9400: eval          Accuracy |  0.61194032\n",
            "\n",
            "Step   9600: Ran 200 train steps in 58.98 secs\n",
            "Step   9600: train CrossEntropyLoss |  1.61571145\n",
            "Step   9600: eval  CrossEntropyLoss |  1.69261110\n",
            "Step   9600: eval          Accuracy |  0.60094851\n",
            "\n",
            "Step   9800: Ran 200 train steps in 59.00 secs\n",
            "Step   9800: train CrossEntropyLoss |  1.59106982\n",
            "Step   9800: eval  CrossEntropyLoss |  1.66280997\n",
            "Step   9800: eval          Accuracy |  0.59234834\n",
            "\n",
            "Step  10000: Ran 200 train steps in 59.18 secs\n",
            "Step  10000: train CrossEntropyLoss |  1.58316708\n",
            "Step  10000: eval  CrossEntropyLoss |  1.53091133\n",
            "Step  10000: eval          Accuracy |  0.62849873\n",
            "\n",
            "Step  10200: Ran 200 train steps in 59.12 secs\n",
            "Step  10200: train CrossEntropyLoss |  1.58498502\n",
            "Step  10200: eval  CrossEntropyLoss |  1.48972738\n",
            "Step  10200: eval          Accuracy |  0.63275611\n",
            "\n",
            "Step  10400: Ran 200 train steps in 59.21 secs\n",
            "Step  10400: train CrossEntropyLoss |  1.56178832\n",
            "Step  10400: eval  CrossEntropyLoss |  1.78456748\n",
            "Step  10400: eval          Accuracy |  0.59096694\n",
            "\n",
            "Step  10600: Ran 200 train steps in 59.13 secs\n",
            "Step  10600: train CrossEntropyLoss |  1.55008757\n",
            "Step  10600: eval  CrossEntropyLoss |  1.36776924\n",
            "Step  10600: eval          Accuracy |  0.66579974\n",
            "\n",
            "Step  10800: Ran 200 train steps in 58.72 secs\n",
            "Step  10800: train CrossEntropyLoss |  1.54637396\n",
            "Step  10800: eval  CrossEntropyLoss |  1.70908916\n",
            "Step  10800: eval          Accuracy |  0.59807462\n",
            "\n",
            "Step  11000: Ran 200 train steps in 59.42 secs\n",
            "Step  11000: train CrossEntropyLoss |  1.54681301\n",
            "Step  11000: eval  CrossEntropyLoss |  1.49578440\n",
            "Step  11000: eval          Accuracy |  0.62654996\n",
            "\n",
            "Step  11200: Ran 200 train steps in 59.67 secs\n",
            "Step  11200: train CrossEntropyLoss |  1.52395034\n",
            "Step  11200: eval  CrossEntropyLoss |  1.64720345\n",
            "Step  11200: eval          Accuracy |  0.61267149\n",
            "\n",
            "Step  11400: Ran 200 train steps in 59.06 secs\n",
            "Step  11400: train CrossEntropyLoss |  1.52402878\n",
            "Step  11400: eval  CrossEntropyLoss |  1.63124490\n",
            "Step  11400: eval          Accuracy |  0.63127691\n",
            "\n",
            "Step  11600: Ran 200 train steps in 59.03 secs\n",
            "Step  11600: train CrossEntropyLoss |  1.53123701\n",
            "Step  11600: eval  CrossEntropyLoss |  1.59253895\n",
            "Step  11600: eval          Accuracy |  0.61376023\n",
            "\n",
            "Step  11800: Ran 200 train steps in 59.31 secs\n",
            "Step  11800: train CrossEntropyLoss |  1.51154578\n",
            "Step  11800: eval  CrossEntropyLoss |  1.62629509\n",
            "Step  11800: eval          Accuracy |  0.60412759\n",
            "\n",
            "Step  12000: Ran 200 train steps in 59.22 secs\n",
            "Step  12000: train CrossEntropyLoss |  1.51156580\n",
            "Step  12000: eval  CrossEntropyLoss |  1.57657623\n",
            "Step  12000: eval          Accuracy |  0.63269359\n",
            "\n",
            "Step  12200: Ran 200 train steps in 59.65 secs\n",
            "Step  12200: train CrossEntropyLoss |  1.50900972\n",
            "Step  12200: eval  CrossEntropyLoss |  1.59611106\n",
            "Step  12200: eval          Accuracy |  0.61777776\n",
            "\n",
            "Step  12400: Ran 200 train steps in 59.93 secs\n",
            "Step  12400: train CrossEntropyLoss |  1.49882412\n",
            "Step  12400: eval  CrossEntropyLoss |  1.57081437\n",
            "Step  12400: eval          Accuracy |  0.61336339\n",
            "\n",
            "Step  12600: Ran 200 train steps in 59.20 secs\n",
            "Step  12600: train CrossEntropyLoss |  1.49674094\n",
            "Step  12600: eval  CrossEntropyLoss |  1.61163485\n",
            "Step  12600: eval          Accuracy |  0.62024355\n",
            "\n",
            "Step  12800: Ran 200 train steps in 59.06 secs\n",
            "Step  12800: train CrossEntropyLoss |  1.48303235\n",
            "Step  12800: eval  CrossEntropyLoss |  1.55392587\n",
            "Step  12800: eval          Accuracy |  0.61441213\n",
            "\n",
            "Step  13000: Ran 200 train steps in 59.32 secs\n",
            "Step  13000: train CrossEntropyLoss |  1.46915388\n",
            "Step  13000: eval  CrossEntropyLoss |  1.55438459\n",
            "Step  13000: eval          Accuracy |  0.63449258\n",
            "\n",
            "Step  13200: Ran 200 train steps in 59.51 secs\n",
            "Step  13200: train CrossEntropyLoss |  1.48325479\n",
            "Step  13200: eval  CrossEntropyLoss |  1.56815708\n",
            "Step  13200: eval          Accuracy |  0.61560905\n",
            "\n",
            "Step  13400: Ran 200 train steps in 58.95 secs\n",
            "Step  13400: train CrossEntropyLoss |  1.47134483\n",
            "Step  13400: eval  CrossEntropyLoss |  1.24378693\n",
            "Step  13400: eval          Accuracy |  0.69168127\n",
            "\n",
            "Step  13600: Ran 200 train steps in 58.86 secs\n",
            "Step  13600: train CrossEntropyLoss |  1.47241104\n",
            "Step  13600: eval  CrossEntropyLoss |  1.42602742\n",
            "Step  13600: eval          Accuracy |  0.65040147\n",
            "\n",
            "Step  13800: Ran 200 train steps in 58.92 secs\n",
            "Step  13800: train CrossEntropyLoss |  1.44804740\n",
            "Step  13800: eval  CrossEntropyLoss |  1.58016789\n",
            "Step  13800: eval          Accuracy |  0.60746002\n",
            "\n",
            "Step  14000: Ran 200 train steps in 59.06 secs\n",
            "Step  14000: train CrossEntropyLoss |  1.46317363\n",
            "Step  14000: eval  CrossEntropyLoss |  1.64407563\n",
            "Step  14000: eval          Accuracy |  0.59685862\n",
            "\n",
            "Step  14200: Ran 200 train steps in 59.07 secs\n",
            "Step  14200: train CrossEntropyLoss |  1.45305717\n",
            "Step  14200: eval  CrossEntropyLoss |  1.51424813\n",
            "Step  14200: eval          Accuracy |  0.62410218\n",
            "\n",
            "Step  14400: Ran 200 train steps in 58.75 secs\n",
            "Step  14400: train CrossEntropyLoss |  1.45574534\n",
            "Step  14400: eval  CrossEntropyLoss |  1.54421329\n",
            "Step  14400: eval          Accuracy |  0.62889069\n",
            "\n",
            "Step  14600: Ran 200 train steps in 58.72 secs\n",
            "Step  14600: train CrossEntropyLoss |  1.45025694\n",
            "Step  14600: eval  CrossEntropyLoss |  1.55070102\n",
            "Step  14600: eval          Accuracy |  0.62830186\n",
            "\n",
            "Step  14800: Ran 200 train steps in 59.14 secs\n",
            "Step  14800: train CrossEntropyLoss |  1.43680382\n",
            "Step  14800: eval  CrossEntropyLoss |  1.42646182\n",
            "Step  14800: eval          Accuracy |  0.65151519\n",
            "\n",
            "Step  15000: Ran 200 train steps in 58.96 secs\n",
            "Step  15000: train CrossEntropyLoss |  1.43928492\n",
            "Step  15000: eval  CrossEntropyLoss |  1.49656403\n",
            "Step  15000: eval          Accuracy |  0.63756984\n",
            "\n",
            "Step  15200: Ran 200 train steps in 58.91 secs\n",
            "Step  15200: train CrossEntropyLoss |  1.42631876\n",
            "Step  15200: eval  CrossEntropyLoss |  1.66487515\n",
            "Step  15200: eval          Accuracy |  0.62539482\n",
            "\n",
            "Step  15400: Ran 200 train steps in 59.14 secs\n",
            "Step  15400: train CrossEntropyLoss |  1.43980622\n",
            "Step  15400: eval  CrossEntropyLoss |  1.69583070\n",
            "Step  15400: eval          Accuracy |  0.60962570\n",
            "\n",
            "Step  15600: Ran 200 train steps in 59.38 secs\n",
            "Step  15600: train CrossEntropyLoss |  1.43521512\n",
            "Step  15600: eval  CrossEntropyLoss |  1.55706000\n",
            "Step  15600: eval          Accuracy |  0.63497823\n",
            "\n",
            "Step  15800: Ran 200 train steps in 59.09 secs\n",
            "Step  15800: train CrossEntropyLoss |  1.42004943\n",
            "Step  15800: eval  CrossEntropyLoss |  1.35894644\n",
            "Step  15800: eval          Accuracy |  0.65572757\n",
            "\n",
            "Step  16000: Ran 200 train steps in 58.80 secs\n",
            "Step  16000: train CrossEntropyLoss |  1.40782785\n",
            "Step  16000: eval  CrossEntropyLoss |  1.60347128\n",
            "Step  16000: eval          Accuracy |  0.62141883\n",
            "\n",
            "Step  16200: Ran 200 train steps in 58.73 secs\n",
            "Step  16200: train CrossEntropyLoss |  1.41586745\n",
            "Step  16200: eval  CrossEntropyLoss |  1.55549502\n",
            "Step  16200: eval          Accuracy |  0.63177806\n",
            "\n",
            "Step  16400: Ran 200 train steps in 58.63 secs\n",
            "Step  16400: train CrossEntropyLoss |  1.40020859\n",
            "Step  16400: eval  CrossEntropyLoss |  1.50106668\n",
            "Step  16400: eval          Accuracy |  0.63351500\n",
            "\n",
            "Step  16600: Ran 200 train steps in 58.56 secs\n",
            "Step  16600: train CrossEntropyLoss |  1.40663266\n",
            "Step  16600: eval  CrossEntropyLoss |  1.62290752\n",
            "Step  16600: eval          Accuracy |  0.62144423\n",
            "\n",
            "Step  16800: Ran 200 train steps in 58.58 secs\n",
            "Step  16800: train CrossEntropyLoss |  1.40279078\n",
            "Step  16800: eval  CrossEntropyLoss |  1.59831655\n",
            "Step  16800: eval          Accuracy |  0.60638297\n",
            "\n",
            "Step  17000: Ran 200 train steps in 58.24 secs\n",
            "Step  17000: train CrossEntropyLoss |  1.39341414\n",
            "Step  17000: eval  CrossEntropyLoss |  1.49556613\n",
            "Step  17000: eval          Accuracy |  0.63885349\n",
            "\n",
            "Step  17200: Ran 200 train steps in 58.26 secs\n",
            "Step  17200: train CrossEntropyLoss |  1.39196718\n",
            "Step  17200: eval  CrossEntropyLoss |  1.53889728\n",
            "Step  17200: eval          Accuracy |  0.63033956\n",
            "\n",
            "Step  17400: Ran 200 train steps in 57.91 secs\n",
            "Step  17400: train CrossEntropyLoss |  1.39234340\n",
            "Step  17400: eval  CrossEntropyLoss |  1.60647810\n",
            "Step  17400: eval          Accuracy |  0.60866714\n",
            "\n",
            "Step  17600: Ran 200 train steps in 58.05 secs\n",
            "Step  17600: train CrossEntropyLoss |  1.37960601\n",
            "Step  17600: eval  CrossEntropyLoss |  1.53744352\n",
            "Step  17600: eval          Accuracy |  0.61819804\n",
            "\n",
            "Step  17800: Ran 200 train steps in 58.14 secs\n",
            "Step  17800: train CrossEntropyLoss |  1.37674308\n",
            "Step  17800: eval  CrossEntropyLoss |  1.38151741\n",
            "Step  17800: eval          Accuracy |  0.65787601\n",
            "\n",
            "Step  18000: Ran 200 train steps in 57.60 secs\n",
            "Step  18000: train CrossEntropyLoss |  1.38085878\n",
            "Step  18000: eval  CrossEntropyLoss |  1.51856709\n",
            "Step  18000: eval          Accuracy |  0.62871283\n",
            "\n",
            "Step  18200: Ran 200 train steps in 57.68 secs\n",
            "Step  18200: train CrossEntropyLoss |  1.37475657\n",
            "Step  18200: eval  CrossEntropyLoss |  1.50602794\n",
            "Step  18200: eval          Accuracy |  0.63516194\n",
            "\n",
            "Step  18400: Ran 200 train steps in 58.29 secs\n",
            "Step  18400: train CrossEntropyLoss |  1.37160707\n",
            "Step  18400: eval  CrossEntropyLoss |  1.63000119\n",
            "Step  18400: eval          Accuracy |  0.60993558\n",
            "\n",
            "Step  18600: Ran 200 train steps in 58.30 secs\n",
            "Step  18600: train CrossEntropyLoss |  1.38145876\n",
            "Step  18600: eval  CrossEntropyLoss |  1.73382103\n",
            "Step  18600: eval          Accuracy |  0.59607583\n",
            "\n",
            "Step  18800: Ran 200 train steps in 58.07 secs\n",
            "Step  18800: train CrossEntropyLoss |  1.35676730\n",
            "Step  18800: eval  CrossEntropyLoss |  1.42407572\n",
            "Step  18800: eval          Accuracy |  0.65318817\n",
            "\n",
            "Step  19000: Ran 200 train steps in 58.63 secs\n",
            "Step  19000: train CrossEntropyLoss |  1.37461317\n",
            "Step  19000: eval  CrossEntropyLoss |  1.26417136\n",
            "Step  19000: eval          Accuracy |  0.67951316\n",
            "\n",
            "Step  19200: Ran 200 train steps in 58.63 secs\n",
            "Step  19200: train CrossEntropyLoss |  1.37073302\n",
            "Step  19200: eval  CrossEntropyLoss |  1.62061453\n",
            "Step  19200: eval          Accuracy |  0.61973602\n",
            "\n",
            "Step  19400: Ran 200 train steps in 58.80 secs\n",
            "Step  19400: train CrossEntropyLoss |  1.35548830\n",
            "Step  19400: eval  CrossEntropyLoss |  1.56442726\n",
            "Step  19400: eval          Accuracy |  0.62918794\n",
            "\n",
            "Step  19600: Ran 200 train steps in 58.75 secs\n",
            "Step  19600: train CrossEntropyLoss |  1.35843277\n",
            "Step  19600: eval  CrossEntropyLoss |  1.52234173\n",
            "Step  19600: eval          Accuracy |  0.62783176\n",
            "\n",
            "Step  19800: Ran 200 train steps in 58.56 secs\n",
            "Step  19800: train CrossEntropyLoss |  1.35774720\n",
            "Step  19800: eval  CrossEntropyLoss |  2.06409335\n",
            "Step  19800: eval          Accuracy |  0.54141003\n",
            "\n",
            "Step  20000: Ran 200 train steps in 58.92 secs\n",
            "Step  20000: train CrossEntropyLoss |  1.35323036\n",
            "Step  20000: eval  CrossEntropyLoss |  1.28555059\n",
            "Step  20000: eval          Accuracy |  0.67150635\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4SCqp5TDbiDu"
      },
      "source": [
        "## Step 6: Model Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7AjmhwEkDJa"
      },
      "source": [
        "### 6-1 Helper functions to tokenize/detokenize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvdTM6Ae0_nU"
      },
      "source": [
        "def tokenize(sentence):\n",
        "    return list(trax.data.tokenize(iter([sentence]), vocab_file = 'en_32k.subword'))[0]\n",
        "\n",
        "def detokenize(tokens):\n",
        "    return trax.data.detokenize(tokens, vocab_file = 'en_32k.subword')"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mGc7B50ukKrm"
      },
      "source": [
        "### 6-2 Helper function to print out the dialogue in color"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9tjBYE_v_XJ"
      },
      "source": [
        "## The helper function to print out the dialogues in colors\n",
        "\n",
        "def print_colored_dialogue(dialogues):\n",
        "\n",
        "    result = []\n",
        "\n",
        "    cur_conversation = \"\"\n",
        "\n",
        "    first_sentence_printed = False\n",
        "\n",
        "    Person1_turn = True\n",
        "\n",
        "    for s in dialogues:\n",
        "\n",
        "        cur_conversation += s\n",
        "\n",
        "        # model predicts Person 2 finishes the sentence\n",
        "        if cur_conversation.endswith(\"Person 1: \"):\n",
        "            if not first_sentence_printed:\n",
        "                first_sentence_printed = True\n",
        "            else:\n",
        "                # print everything before \"Person 1: \"\n",
        "                print(colored(\"Person 2: \" + cur_conversation.split(\"Person 1: \")[0].strip(), 'red'))\n",
        "                cur_conversation = \"\"\n",
        "                Person1_turn = True\n",
        "\n",
        "        # model predicts Person 1 finished the sentence\n",
        "        elif cur_conversation.endswith(\"Person 2: \"):\n",
        "            # print everything before \"Person 2: \"\n",
        "            print(colored(\"Person 1: \" + cur_conversation.split(\"Person 2: \")[0].strip(), 'blue'))\n",
        "            cur_conversation = \"\"\n",
        "            Person1_turn = False\n",
        "\n",
        "    # print remaining sentences\n",
        "    if Person1_turn:\n",
        "        print(colored(\"Person 1: \" + cur_conversation, 'blue'))\n",
        "    else:\n",
        "        print(colored(\"Person 2: \" + cur_conversation, 'red'))"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24_p68egtd0D"
      },
      "source": [
        "### 6-3 Predict on the test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pVuT67_CnxZ",
        "outputId": "f4910248-86a6-4f94-8a27-4c74f5947778",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# grab a batch from test_stream\n",
        "test_x, test_y, test_w = next(test_stream)\n",
        "print(\"Batch_size = {}\".format(test_x.shape[0]))\n",
        "\n",
        "# choose the first example\n",
        "sample_x = test_x[0][None, :]\n",
        "\n",
        "print(\"\\nInput dialogue:\")\n",
        "print_colored_dialogue(detokenize(sample_x[0]))\n",
        "\n",
        "pred = loop.eval_model(sample_x)\n",
        "pred_token = pred.argmax(axis = -1)\n",
        "\n",
        "print(\"\\nOutput dialogue:\")\n",
        "print_colored_dialogue(detokenize(pred_token[0]))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Batch_size = 4\n",
            "Input dialogue:\n",
            "\u001b[34mPerson 1: Person 1: I am  looking for a place to stay. The hotel should be in the type of guesthouse and should include free wifi\u001b[0m\n",
            "\u001b[31mPerson 2: There are 23 guesthouses with free wifi. What price range or area do you prefer?\u001b[0m\n",
            "\u001b[34mPerson 1: I would prefer a price range of expensive\u001b[0m\n",
            "\u001b[31mPerson 2: It seems that there are no guesthouses in the expensive price range. Can I offer you a different price range or a different type of hotel?\u001b[0m\n",
            "\u001b[34mPerson 1: How about moderate price range with a star of 4?\u001b[0m\n",
            "\u001b[31mPerson 2: There are several. Do you have a preference for area?\u001b[0m\n",
            "\u001b[34mPerson 1: Area doesn't matter but I need to know if they have free parking\u001b[0m\n",
            "\u001b[31mPerson 2: I have discovered 9 choices fitting your description. May I recommend the Archway House? It's on Gilbert Road.\u001b[0m\n",
            "\u001b[34mPerson 1: Sounds great, Thank you.\u001b[0m\n",
            "\u001b[31mPerson 2: You're welcome. Would you like me to make a reservation in your name?\u001b[0m\n",
            "\u001b[34mPerson 1: Yes please make a reservation in my name. Thank you.\u001b[0m\n",
            "\u001b[31mPerson 2: I will need to know the day you will be arriving, the amount of days and for how many people before making the reservation.\u001b[0m\n",
            "\u001b[34mPerson 1: I'm sorry I don't need a reservation right now. Can you just tell me if they offer free parking?\u001b[0m\n",
            "\u001b[31mPerson 2: Yes, Archway House offers free parking. May I help with something else?\u001b[0m\n",
            "\u001b[34mPerson 1: Great, thanks. That is all I needed.\u001b[0m\n",
            "\u001b[31mPerson 2: Should I book that for you?\u001b[0m\n",
            "\u001b[34mPerson 1: No, I can book myself later.  Thanks.  Good bye.\u001b[0m\n",
            "\u001b[31mPerson 2: Thank you for using our services. Do you require any further assistance?\u001b[0m\n",
            "\n",
            "Output dialogue:\n",
            "\u001b[34mPerson 1: Person 1: I am looking looking for a place to stay. The hotel should be in the type of guesthouse and should have free parkfi\u001b[0m\n",
            "\u001b[31mPerson 2: I are 33 guesthouses that free parkfi. Do area range are price are you prefer?\u001b[0m\n",
            "\u001b[31mPerson 2: I would like a guesrange in a. 2: I looks to is are 3 1 thouses in the area price range. PersonI look a? different price range? area different price of hotel?\u001b[0m\n",
            "\u001b[34mPerson 1: How about one prirange? a 4 rating 4 star\u001b[0m\n",
            "\u001b[31mPerson 2: I are 3 guesDo you have a preference for the or\u001b[0m\n",
            "\u001b[31mPerson 2: I doesn't matter. I do to book the it have free parking. 2: I have the to entries ces. ting your criteria. Do I suggest d the Acoway House? Person' s a the as,\u001b[0m\n",
            "\u001b[31mPerson 2: That s good. can k you. Can 2: Than' re welcome. Can uld you like me to book a reservation? the party?\u001b[0m\n",
            "\u001b[34mPerson 1: No, , a reservation at the party. Personk you.\u001b[0m\n",
            "\u001b[31mPerson 2: How'book more know what day you'be checking and how number of your you how how many people will I your reservation for\u001b[0m\n",
            "\u001b[34mPerson 1: I'll sorry, don't need a reservation. now. I you just tell me the there have free parking?\u001b[0m\n",
            "\u001b[31mPerson 2: Yes, it way house has free parking. PersonI help with anything else?\u001b[0m\n",
            "\u001b[34mPerson 1: No, that for I'all I need.\u001b[0m\n",
            "\u001b[31mPerson 2: Thanld I hope a for you.\u001b[0m\n",
            "\u001b[34mPerson 1: No, thando do it elf, . Person for Personbye.\u001b[0m\n",
            "\u001b[31mPerson 2: Thank you for using our service.Have you need any more assistance? please!!or or or!. ? ? . ? ? ? ? . . . . . . . . . . . . . . . . . than. . . than. than. than. . . . . than. . . . . than. . . . . . . . . . . . . . . . . . . . . . . . . . . . between. . . . . north. . north north. . north. than between. . north north north between. . north. . . between. . between between. between. between north north\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wkstm2sYtypY"
      },
      "source": [
        "### 6-4 Predict on custom starter sentence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQAR8Ya7kx9k"
      },
      "source": [
        "6-4-1 Helper function to generate the next token"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhGKKIAyRk5F"
      },
      "source": [
        "def generate_next_token(current_tokens, model):\n",
        "\n",
        "    \"\"\"\n",
        "    Generate the next token\n",
        "    \n",
        "    Inputs\n",
        "            current_tokens: <list of int> currently generated token so far\n",
        "            model: <trax model> the model for the prediction\n",
        "    \n",
        "    Output\n",
        "            next_token: <int> the next token generated by the model\n",
        "    \"\"\"\n",
        "\n",
        "    # number of tokens generated so far\n",
        "    current_tokens_length = len(current_tokens)\n",
        "   \n",
        "    # find the next power of 2 to be the final length after padding\n",
        "    final_padded_length = 2**int(np.ceil(np.log2(current_tokens_length + 1)))\n",
        "\n",
        "    # caucluate the number of zeros to pad\n",
        "    to_pad_length = final_padded_length - current_tokens_length\n",
        "\n",
        "    # padding\n",
        "    padded_current_tokens = np.array(current_tokens.tolist() + [0 for _ in range(to_pad_length)])[None, :]\n",
        "\n",
        "    # use the model to predict the log probabilities of the next token\n",
        "    model_output, _ = model((padded_current_tokens, padded_current_tokens))\n",
        "\n",
        "    # (note) model_output has shape (batch_size, len_of_whole_token_list, vocab_size)\n",
        "    # only take the log probability distribution of the last token\n",
        "    next_token_logprob = model_output[0, current_tokens_length, :]\n",
        "\n",
        "    # select the token with the largest log probability\n",
        "    next_token = int(np.argmax(next_token_logprob))\n",
        "\n",
        "    return next_token"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPUBtYCLk2dT"
      },
      "source": [
        "#### 6-4-2 Helper function to continue the conversation token by token"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDMMVNS0Ruai"
      },
      "source": [
        "def extend_dialogue(current_dialogue, model, maximum_number_extension = 100):\n",
        "\n",
        "    \"\"\"\n",
        "    Extend the dialogue\n",
        "\n",
        "    Inputs \n",
        "            current_dialogue: <str> the starting dialogue\n",
        "            model: <trax model> the chatbot model\n",
        "            maximum_number_extension: <int> maximum number of tokens to generate\n",
        "\n",
        "    Output\n",
        "            complete_dialogue: <str> the complete dialogue\n",
        "    \"\"\"\n",
        "\n",
        "    current_tokens_list = tokenize(current_dialogue)\n",
        "\n",
        "    num_tokens_generated = 0\n",
        "\n",
        "    while num_tokens_generated <= maximum_number_extension:\n",
        "        # given current_tokens_list, generate the next token\n",
        "        next_output_token = generate_next_token(current_tokens_list, model)\n",
        "\n",
        "        current_tokens_list = current_tokens_list.tolist()\n",
        "\n",
        "        current_tokens_list.append(next_output_token)\n",
        "\n",
        "        current_tokens_list = np.array(current_tokens_list)\n",
        "\n",
        "        num_tokens_generated += 1\n",
        "\n",
        "    # maximum number of tokens reached, output the detokenized dialogue\n",
        "    complete_dialogue = trax.data.detokenize(current_tokens_list, vocab_file = 'en_32k.subword')\n",
        "\n",
        "    return complete_dialogue"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BdCGLBJolCoj"
      },
      "source": [
        "#### 6-4-3 Custom starter sentences\n",
        "\n",
        "Use and starter sentences as `dialogue_seed`. However, it has to begin with \"Person 1:\" and end with \"Person 2: \""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "An4wnkFNTN2U",
        "outputId": "66948853-857d-41f8-d60e-b5efbb23fbb5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "## Example wehre Person 1 asks for an avocado for no reason\n",
        "\n",
        "dialogue_seed = \"Person 1: Um... Can I have some avocado? Person 2: \"\n",
        "\n",
        "complete_dialogue = extend_dialogue(dialogue_seed, loop.eval_model, maximum_number_extension = 100)\n",
        "\n",
        "print_colored_dialogue(complete_dialogue)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34mPerson 1: Person 1: Um... Can I have some avocado?\u001b[0m\n",
            "\u001b[31mPerson 2: I can't help you with that. What type of information are you looking for?\u001b[0m\n",
            "\u001b[34mPerson 1: I'm looking for a train to Cambridge that leaves after 15:00.\u001b[0m\n",
            "\u001b[31mPerson 2: I have train TR7424 that leaves at 17:11 and arrive in Cambridge at 18:55. Would you like me to book it for you?\u001b[0m\n",
            "\u001b[34mPerson 1: Yes, I need 5 tickets.\u001b[0m\n",
            "\u001b[31mPerson 2: Booking was successful, the total fee is\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lcztajkT1PUr",
        "outputId": "bf620bf2-de76-4eec-a176-f3ef7c048a85",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "## Example where Person 1 wants to find a restaurant\n",
        "\n",
        "dialogue_seed = \"Person 1: Where is the Japanese restaurant? Person 2: \"\n",
        "\n",
        "complete_dialogue = extend_dialogue(dialogue_seed, loop.eval_model, maximum_number_extension = 100)\n",
        "\n",
        "print_colored_dialogue(complete_dialogue)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34mPerson 1: Person 1: Where is the Japanese restaurant?\u001b[0m\n",
            "\u001b[31mPerson 2: The Addenbell is located at 32 Bridge Street City Centre. Would you like me to book a table?\u001b[0m\n",
            "\u001b[34mPerson 1: No, I'd like to book a table for 7 people at 14:00 on Saturday.\u001b[0m\n",
            "\u001b[31mPerson 2: I have booked you a table for 7 at the Bedouin. Your reference number is XYZ1Z.\u001b[0m\n",
            "\u001b[34mPerson 1: Thanks, that's all I need.\u001b[0m\n",
            "\u001b[31mPerson 2: You're welcome\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PIBja9NVfWO",
        "outputId": "b15ee6cb-5268-4857-a78d-4c78941cbad6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "## Example where Person 1 wants to find a post office\n",
        "\n",
        "dialogue_seed = \"Person 1: Where can I find the post office? Person 2: \"\n",
        "\n",
        "complete_dialogue = extend_dialogue(dialogue_seed, loop.eval_model, maximum_number_extension = 100)\n",
        "\n",
        "print_colored_dialogue(complete_dialogue)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34mPerson 1: Person 1: Where can I find the post office?\u001b[0m\n",
            "\u001b[31mPerson 2: The Cambridge Belfry is located at 5 Greens Road.\u001b[0m\n",
            "\u001b[34mPerson 1: What is the postcode?\u001b[0m\n",
            "\u001b[31mPerson 2: The postcode is cb21sj.\u001b[0m\n",
            "\u001b[34mPerson 1: Thanks, that's all I need.\u001b[0m\n",
            "\u001b[31mPerson 2: You're welcome. Have a great day!and enjoy your day!us.\u001b[0m\n",
            "\u001b[34mPerson 1: Thanks, you too.\u001b[0m\n",
            "\u001b[31mPerson 2: You're welcome. Have a great day!.Person 1\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZuBQb0JdfR9n",
        "outputId": "fe7f73c5-cb0c-4fd4-90f3-1d55e6364a92",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "## Example where Person 1 wants book a hotel room\n",
        "\n",
        "dialogue_seed = \"Person 1: Hello, I'm wondering if I can book a hotel room tonight? Person 2: \"\n",
        "\n",
        "complete_dialogue = extend_dialogue(dialogue_seed, loop.eval_model, maximum_number_extension = 200)\n",
        "\n",
        "print_colored_dialogue(complete_dialogue)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34mPerson 1: Person 1: Hello, I'm wondering if I can book a hotel room tonight?\u001b[0m\n",
            "\u001b[31mPerson 2: I can help with that. What area of town would you like to stay in?\u001b[0m\n",
            "\u001b[34mPerson 1: I'd like to stay in the east, please.\u001b[0m\n",
            "\u001b[31mPerson 2: I have three options for you. The Huntingdon Marriott Hotel, and the rest of your stay.\u001b[0m\n",
            "\u001b[34mPerson 1: I'd like to book it for 2 people and 4 nights starting from wednesday.\u001b[0m\n",
            "\u001b[31mPerson 2: I have booked your hotel for 4 people for 2 nights starting on Saturday. Your reference number is X1Z1Z1.\u001b[0m\n",
            "\u001b[34mPerson 1: Thanks, that's all I need.\u001b[0m\n",
            "\u001b[31mPerson 2: You're welcome. Have a great day!!!!!!.\u001b[0m\n",
            "\u001b[34mPerson 1: Thank you, goodbye.\u001b[0m\n",
            "\u001b[31mPerson 2: Thank you for using our service. Have a great day!.\u001b[0m\n",
            "\u001b[34mPerson 1: Thanks, you too.\u001b[0m\n",
            "\u001b[31mPerson 2: You're welcome. \u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSAP-1vfmCIK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
